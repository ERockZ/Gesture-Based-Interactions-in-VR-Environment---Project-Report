\section{Related Work}
Over the years, there has been a multitude of research on various interaction techniques in virtual environments. \cite{bowman1999} created a methodology for design of interactions in virtual environments where they also established a taxonomy of different techniques for selection and manipulation of objects, e.g, ways to perform different steps of the selection process, such as indication of the intent and selection of the object itself. Basically, these interaction techniques as listed in \cite{bowman1999}, are being used and researched in recent publications as well.

The combination of gaze and touch/gesture seems to be a very popular approach to interaction. Usually, in these scenarios, users can use gaze to select objects and touch or gestures to manipulate them afterwards. \cite{pfeuffer2014} compares the gaze-touch for touch screens with the direct touch technique where people use only their hands for pointing and selecting. Among the identified benefits of the gaze-touch approach are better reachability, less physical movement and less fatigue, absence of occlusion and higher interaction speed. However, using this method also results in various challenges, e.g., inaccuracies may be introduced due to eyetracking in densely populated environments. Another important issue results from the fact that users do not need to keep their hands close to the object as they start manipulating, so they might have to interrupt their action if they initially positioned their hands at the boundaries of the tracking space and went beyond them in the process. \cite{deng2017} investigates the reasons for this problem, its relevance to multimodal interactions and possible solutions.

Other interaction techniques are researched as well. \cite{hurst2013gesture} explores the gesture-based operation in mobile augmented reality environments, in particular, using the device camera to capture gestures for manipulation of mid-air virtual objects. \cite{gugenheimer2016} introduces the model of mobile head-mounted displays which has a touch-sensitive surface attached to its backside, so that users can interact with virtual objects using the direct touch technique. \cite{reinschluessel2017} focuses on touch-free interactions with hand and foot gestures for computer-assisted surgery where sterility is of the essence. \cite{clifford2017} suggests a Star Wars inspired "telekinesis" approach implemented with head gestures and spatial controllers, e.g., HTC Vive.